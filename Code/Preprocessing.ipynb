{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2581c86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7208604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>interview_date</th>\n",
       "      <th>country</th>\n",
       "      <th>NPS</th>\n",
       "      <th>comment</th>\n",
       "      <th>translated_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-11</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>Die Vertragsänderung meiner Mutter wurde nicht...</td>\n",
       "      <td>My mother&amp;#39;s contract change did not go thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-07-19</td>\n",
       "      <td>Poland</td>\n",
       "      <td>0</td>\n",
       "      <td>ebok nie dziala - brak wgladu do Faktur</td>\n",
       "      <td>ebok does not work - no access to invoices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>Italy</td>\n",
       "      <td>8</td>\n",
       "      <td>NON SAPREI. PERCHE' MI SONO TROVATO BENE SEMPR...</td>\n",
       "      <td>I WOULD NOT KNOW. BECAUSE I HAVE ALWAYS FOUND ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-08-04</td>\n",
       "      <td>Germany</td>\n",
       "      <td>10</td>\n",
       "      <td>Service auch telefonisch immer erreichbar und ...</td>\n",
       "      <td>Service is always available by phone and you g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2022-08-15</td>\n",
       "      <td>Poland</td>\n",
       "      <td>9</td>\n",
       "      <td>Fachowosc,kompetencje i kultura pracownika</td>\n",
       "      <td>Professionalism, competence and employee culture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID interview_date  country NPS  \\\n",
       "0   1     2022-05-11  Germany   0   \n",
       "1   2     2022-07-19   Poland   0   \n",
       "2   3     2022-12-14    Italy   8   \n",
       "3   4     2022-08-04  Germany  10   \n",
       "4   5     2022-08-15   Poland   9   \n",
       "\n",
       "                                             comment  \\\n",
       "0  Die Vertragsänderung meiner Mutter wurde nicht...   \n",
       "1            ebok nie dziala - brak wgladu do Faktur   \n",
       "2  NON SAPREI. PERCHE' MI SONO TROVATO BENE SEMPR...   \n",
       "3  Service auch telefonisch immer erreichbar und ...   \n",
       "4         Fachowosc,kompetencje i kultura pracownika   \n",
       "\n",
       "                                  translated_comment  \n",
       "0  My mother&#39;s contract change did not go thr...  \n",
       "1         ebok does not work - no access to invoices  \n",
       "2  I WOULD NOT KNOW. BECAUSE I HAVE ALWAYS FOUND ...  \n",
       "3  Service is always available by phone and you g...  \n",
       "4   Professionalism, competence and employee culture  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"anonymized_challenge_dataset.csv\"\n",
    "dataset = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08155959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 503952 entries, 0 to 503951\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   ID                  503952 non-null  int64 \n",
      " 1   interview_date      502936 non-null  object\n",
      " 2   country             502566 non-null  object\n",
      " 3   NPS                 500699 non-null  object\n",
      " 4   translated_comment  497321 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 19.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning\n",
    "dataset = dataset.drop(\"comment\", axis = 1)\n",
    "print(dataset.info())\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = dataset.isnull().sum()\n",
    "\n",
    "# Initial analysis of NPS values (checking for outliers or inappropriate values)\n",
    "dataset['NPS'] = pd.to_numeric(dataset['NPS'], errors='coerce')\n",
    "nps_summary = dataset['NPS'].describe()\n",
    "\n",
    "# Convert 'interview_date' to datetime\n",
    "dataset['interview_date'] = pd.to_datetime(dataset['interview_date'], errors='coerce')\n",
    "\n",
    "# Check data types\n",
    "data_types = dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d01f389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                       0\n",
       "interview_date        1016\n",
       "country               1386\n",
       "NPS                   3253\n",
       "translated_comment    6631\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73a84c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                             int64\n",
       "interview_date        datetime64[ns]\n",
       "country                       object\n",
       "NPS                          float64\n",
       "translated_comment            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "003721e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    500525.000000\n",
       "mean          7.711479\n",
       "std           2.880806\n",
       "min           0.000000\n",
       "25%           7.000000\n",
       "50%           9.000000\n",
       "75%          10.000000\n",
       "max          99.000000\n",
       "Name: NPS, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['NPS'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "145e8b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[dataset['NPS'] > 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f117b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'missing_values': {'ID': 0,\n",
       "  'interview_date': 0,\n",
       "  'country': 0,\n",
       "  'NPS': 0,\n",
       "  'translated_comment': 0},\n",
       " 'nps_summary_cleaned': {'count': 500510.0,\n",
       "  'mean': 7.708743082056302,\n",
       "  'std': 2.837169444802836,\n",
       "  'min': 0.0,\n",
       "  '25%': 7.0,\n",
       "  '50%': 9.0,\n",
       "  '75%': 10.0,\n",
       "  'max': 10.0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigating the outlier in NPS\n",
    "dataset = dataset[dataset['NPS'] < 11]\n",
    "\n",
    "# Recheck NPS summary after handling outliers\n",
    "nps_summary_cleaned = dataset['NPS'].describe()\n",
    "\n",
    "dataset = dataset[dataset['translated_comment'].notnull()]\n",
    "dataset.dropna(subset=['interview_date'], inplace=True)\n",
    "\n",
    "\n",
    "# Convert results to a dictionary for easier interpretation\n",
    "cleaning_results = {\n",
    "    \"missing_values\": dataset.isnull().sum().to_dict(),\n",
    "    \"nps_summary_cleaned\": nps_summary_cleaned.to_dict()\n",
    "}\n",
    "\n",
    "cleaning_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40a3eca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Netherlands       153148\n",
       "Czech             130030\n",
       "Germany            48484\n",
       "Romania            41674\n",
       "Poland             34981\n",
       "Italy              32409\n",
       "Sweden             30512\n",
       "Hungary            24994\n",
       "Czech Republic       667\n",
       "United Kingdom       397\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove junk and map Czech to Czech Republic\n",
    "keep_countries = ['Germany', 'Poland', 'Italy', 'Romania', 'Sweden', 'Netherlands', 'Czech',\n",
    "                          'Czech Republic', 'United Kingdom', 'Hungary']\n",
    "df = dataset[dataset['country'].isin(keep_countries)]\n",
    "df['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15298e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_mapping = {'Czech Republic': 'Czech'}\n",
    "df['country'] = df['country'].replace(country_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d05a76aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Netherlands       153148\n",
       "Czech             130697\n",
       "Germany            48484\n",
       "Romania            41674\n",
       "Poland             34981\n",
       "Italy              32409\n",
       "Sweden             30512\n",
       "Hungary            24994\n",
       "United Kingdom       397\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63a9d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize customers into different types\n",
    "def customerType(dataset):\n",
    "    if dataset[\"NPS\"] >= 9:\n",
    "        return \"promoters\"\n",
    "    elif (dataset[\"NPS\"] == 7 or dataset[\"NPS\"] == 8):\n",
    "        return \"passives\"\n",
    "    elif dataset[\"NPS\"] <= 6:\n",
    "        return \"detractors\" \n",
    "    \n",
    "df[\"customer_type\"] = dataset.apply(customerType, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4466e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_length'] = df['translated_comment'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a5437ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/adam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/adam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/adam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# Downloading necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "sw_nltk = stopwords.words('english')\n",
    "sw_nltk.remove('not')\n",
    "sw_nltk.remove('no')\n",
    "sw_nltk.remove('nor')\n",
    "sw_nltk.remove(\"don't\")\n",
    "# sw_nltk.remove(\"aren't\")\n",
    "# sw_nltk.remove(\"couldn't\")\n",
    "# sw_nltk.remove(\"didn't\")\n",
    "stop_words = [word for word in sw_nltk if word not in sw_nltk[-36:]]\n",
    "# sw_nltk.remove([sw_nltk[-36:]])\n",
    "\n",
    "# Initializing the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0cb874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def preprocess_text(text):\n",
    "    # Convert to lower case\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenization\n",
    "    words = nltk.word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Joining back into a string\n",
    "    text = ' '.join(words)\n",
    "    return text\n",
    "\n",
    "# df['comment_preprocessed'] = df['comment'].apply(preprocess_text)\n",
    "df[\"translated_comment\"] = df[\"translated_comment\"].str.replace(\"&#39;\",\"\\'\")\n",
    "df[\"translated_comment\"] = df[\"translated_comment\"].str.replace(\"nee\", \"no\", regex = False)\n",
    "df[\"translated_comment\"] = df[\"translated_comment\"].str.replace(\"Nee\", \"No\", regex = False)\n",
    "df[\"translated_comment\"] = df[\"translated_comment\"].str.replace(\"essent\", \"eon\", regex = False)\n",
    "df[\"translated_comment\"] = df[\"translated_comment\"].str.replace(\"Essent\", \"Eon\", regex = False)\n",
    "df[\"translated_comment\"] = df[\"translated_comment\"].str.replace(\"quot\", \"\", regex = False)\n",
    "\n",
    "df[\"translated_comment\"] = df[\"translated_comment\"].replace(r'\\d+', '', regex=True)\n",
    "\n",
    "df['translated_comment_preprocessed'] = df['translated_comment'].apply(preprocess_text)\n",
    "\n",
    "# Define a function to lemmatize text\n",
    "def lemmatize_text(text):\n",
    "    # Tokenize the sentence\n",
    "    tokens = word_tokenize(text)\n",
    "    # Lemmatize each word in the sentence\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    # Join the lemmatized tokens back into a sentence\n",
    "    lemmatized_sentence = ' '.join(lemmatized_tokens)\n",
    "    return lemmatized_sentence\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df['translated_comment_preprocessed'] = df['translated_comment_preprocessed'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0910b4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NPS</th>\n",
       "      <th>translated_comment</th>\n",
       "      <th>translated_comment_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>My mother's contract change did not go through...</td>\n",
       "      <td>mother contract change not go expected bank de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>ebok does not work - no access to invoices</td>\n",
       "      <td>ebok not work no access invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>I WOULD NOT KNOW. BECAUSE I HAVE ALWAYS FOUND ...</td>\n",
       "      <td>would not know always found well eon output pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Service is always available by phone and you g...</td>\n",
       "      <td>service always available phone get help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Professionalism, competence and employee culture</td>\n",
       "      <td>professionalism competence employee culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0</td>\n",
       "      <td>easy to read and simple IT system</td>\n",
       "      <td>easy read simple system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Advice 'at the window' in the Warsaw center of...</td>\n",
       "      <td>advice window warsaw center mokotow efficient ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.0</td>\n",
       "      <td>very quickly the problem was solved, the count...</td>\n",
       "      <td>quickly problem solved counter not register ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>The contract I got</td>\n",
       "      <td>contract got</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Better price.</td>\n",
       "      <td>better price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>service transparency, intuitiveness</td>\n",
       "      <td>service transparency intuitiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.0</td>\n",
       "      <td>So far I have only signed the contract. That w...</td>\n",
       "      <td>far signed contract easy change also work well...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.0</td>\n",
       "      <td>it took too long</td>\n",
       "      <td>took long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9.0</td>\n",
       "      <td>the fact that I can pay through the bank, it i...</td>\n",
       "      <td>fact pay bank direct debit online application ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>No invoices sent, total inability to take over...</td>\n",
       "      <td>no invoice sent total inability take new clien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.0</td>\n",
       "      <td>The customer evaluates dth well, with whom he ...</td>\n",
       "      <td>customer evaluates dth well good contact hand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.0</td>\n",
       "      <td>High prices</td>\n",
       "      <td>high price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Quick - easy and pleasant</td>\n",
       "      <td>quick easy pleasant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Very nice service and professionalism of the l...</td>\n",
       "      <td>nice service professionalism lady called</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.0</td>\n",
       "      <td>beat caught</td>\n",
       "      <td>beat caught</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NPS                                 translated_comment  \\\n",
       "0    0.0  My mother's contract change did not go through...   \n",
       "1    0.0         ebok does not work - no access to invoices   \n",
       "2    8.0  I WOULD NOT KNOW. BECAUSE I HAVE ALWAYS FOUND ...   \n",
       "3   10.0  Service is always available by phone and you g...   \n",
       "4    9.0   Professionalism, competence and employee culture   \n",
       "5   10.0                  easy to read and simple IT system   \n",
       "6   10.0  Advice 'at the window' in the Warsaw center of...   \n",
       "7   10.0  very quickly the problem was solved, the count...   \n",
       "8    1.0                                 The contract I got   \n",
       "9    8.0                                      Better price.   \n",
       "10  10.0                service transparency, intuitiveness   \n",
       "11   8.0  So far I have only signed the contract. That w...   \n",
       "12   5.0                                   it took too long   \n",
       "13   9.0  the fact that I can pay through the bank, it i...   \n",
       "14   0.0  No invoices sent, total inability to take over...   \n",
       "15   7.0  The customer evaluates dth well, with whom he ...   \n",
       "16   5.0                                        High prices   \n",
       "17  10.0                          Quick - easy and pleasant   \n",
       "18  10.0  Very nice service and professionalism of the l...   \n",
       "19   8.0                                        beat caught   \n",
       "\n",
       "                      translated_comment_preprocessed  \n",
       "0   mother contract change not go expected bank de...  \n",
       "1                     ebok not work no access invoice  \n",
       "2   would not know always found well eon output pr...  \n",
       "3             service always available phone get help  \n",
       "4         professionalism competence employee culture  \n",
       "5                             easy read simple system  \n",
       "6   advice window warsaw center mokotow efficient ...  \n",
       "7   quickly problem solved counter not register ca...  \n",
       "8                                        contract got  \n",
       "9                                        better price  \n",
       "10                 service transparency intuitiveness  \n",
       "11  far signed contract easy change also work well...  \n",
       "12                                          took long  \n",
       "13  fact pay bank direct debit online application ...  \n",
       "14  no invoice sent total inability take new clien...  \n",
       "15  customer evaluates dth well good contact hand ...  \n",
       "16                                         high price  \n",
       "17                                quick easy pleasant  \n",
       "18           nice service professionalism lady called  \n",
       "19                                        beat caught  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['NPS', 'translated_comment', 'translated_comment_preprocessed']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0d79866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 497296 entries, 0 to 503951\n",
      "Data columns (total 8 columns):\n",
      " #   Column                           Non-Null Count   Dtype         \n",
      "---  ------                           --------------   -----         \n",
      " 0   ID                               497296 non-null  int64         \n",
      " 1   interview_date                   497296 non-null  datetime64[ns]\n",
      " 2   country                          497296 non-null  object        \n",
      " 3   NPS                              497296 non-null  float64       \n",
      " 4   translated_comment               497296 non-null  object        \n",
      " 5   customer_type                    497296 non-null  object        \n",
      " 6   comment_length                   497296 non-null  int64         \n",
      " 7   translated_comment_preprocessed  497296 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(4)\n",
      "memory usage: 34.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset = df.copy()\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dbe346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_numeric(text):\n",
    "    \"\"\"\n",
    "    Check if the given text is entirely numeric.\n",
    "    \"\"\"\n",
    "    return text.isdigit() if isinstance(text, str) else False\n",
    "\n",
    "# Filter out rows where the comments are entirely numeric\n",
    "dataset = dataset[~dataset['translated_comment_preprocessed'].apply(is_numeric)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "582963d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_emojis(text):\n",
    "    \"\"\"\n",
    "    Remove emojis from the given text.\n",
    "    \"\"\"\n",
    "    # Emoji patterns\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# Apply the function to the relevant columns\n",
    "dataset['translated_comment_preprocessed'] = dataset['translated_comment_preprocessed'].apply(remove_emojis)\n",
    "dataset['translated_comment'] = dataset['translated_comment'].apply(remove_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa9d11d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset['comment_length'] > 1]\n",
    "\n",
    "dataset['comment_length_2'] = dataset['translated_comment_preprocessed'].str.len()\n",
    "dataset = dataset[dataset['comment_length_2'] > 0]\n",
    "\n",
    "dataset = dataset.dropna(subset=[\"translated_comment_preprocessed\"])\n",
    "dataset.drop('comment_length_2', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48d1582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('cleaned_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b387a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 10 percent of dataset for faster computing in some algorithms\n",
    "df_percent = dataset.sample(frac=0.1)\n",
    "df_percent.to_csv('cleaned_dataset_10percent.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b812b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
